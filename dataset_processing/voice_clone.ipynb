{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Clone (Voice Conversion) — Folder Batch\n",
    "\n",
    "Applies voice conversion to every WAV in a folder using one or more **reference voice** samples.\n",
    "Produces one output subfolder per reference voice.\n",
    "\n",
    "### Supported engines\n",
    "\n",
    "| Engine | Backend | Notes |\n",
    "|--------|---------|-------|\n",
    "| **chatterbox** | PyTorch | Best quality, needs GPU |\n",
    "| **chatterbox_onnx** | ONNX Runtime | CPU-friendly, slightly lower quality |\n",
    "\n",
    "---\n",
    "\n",
    "> GPU strongly recommended for `chatterbox`. CPU ok for `chatterbox_onnx`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "# ════════════════════════════════════════════\n",
    "# ⚙️  CONFIGURATION\n",
    "# ════════════════════════════════════════════\n",
    "os.environ.setdefault(\"INPUT_DIR\",       \"/data/audio_in\")         # Source WAVs\n",
    "os.environ.setdefault(\"OUTPUT_DIR\",      \"/data/audio_cloned\")     # Output root (subdir per voice)\n",
    "os.environ.setdefault(\"REF_VOICES_DIR\",  \"/data/ref_voices\")       # Folder of reference voice WAVs\n",
    "os.environ.setdefault(\"VC_ENGINE\",       \"chatterbox\")             # chatterbox | chatterbox_onnx\n",
    "os.environ.setdefault(\"VC_DEVICE\",       \"cuda\")                   # cuda | cpu\n",
    "\n",
    "INPUT_DIR      = os.environ[\"INPUT_DIR\"]\n",
    "OUTPUT_DIR     = os.environ[\"OUTPUT_DIR\"]\n",
    "REF_VOICES_DIR = os.environ[\"REF_VOICES_DIR\"]\n",
    "VC_ENGINE      = os.environ[\"VC_ENGINE\"]\n",
    "VC_DEVICE      = os.environ[\"VC_DEVICE\"]\n",
    "\n",
    "print(f\"Input:       {INPUT_DIR}\")\n",
    "print(f\"Output:      {OUTPUT_DIR}\")\n",
    "print(f\"Ref voices:  {REF_VOICES_DIR}\")\n",
    "print(f\"Engine:      {VC_ENGINE}\")\n",
    "print(f\"Device:      {VC_DEVICE}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "vc_engine = os.environ.get(\"VC_ENGINE\", \"chatterbox\")\n",
    "if vc_engine == \"chatterbox_onnx\":\n",
    "    !pip install --quiet --break-system-packages chatterbox-onnx tqdm\n",
    "else:\n",
    "    !pip install --quiet --break-system-packages chatterbox torch torchaudio tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Discover reference voices\n",
    "ref_files = sorted(Path(REF_VOICES_DIR).rglob(\"*.wav\"))\n",
    "if not ref_files:\n",
    "    raise FileNotFoundError(f\"No .wav files found in {REF_VOICES_DIR}\")\n",
    "print(f\"Found {len(ref_files)} reference voice(s)\")\n",
    "\n",
    "# Discover source audio\n",
    "source_files = sorted(Path(INPUT_DIR).rglob(\"*.wav\"))\n",
    "print(f\"Found {len(source_files)} source audio files\")\n",
    "\n",
    "# Load VC model once\n",
    "print(f\"Loading {VC_ENGINE} model on {VC_DEVICE}...\")\n",
    "if VC_ENGINE == \"chatterbox_onnx\":\n",
    "    from chatterbox_onnx import ChatterboxOnnx\n",
    "    vc_model = ChatterboxOnnx(device=VC_DEVICE)\n",
    "else:\n",
    "    from chatterbox.vc import ChatterboxVC\n",
    "    vc_model = ChatterboxVC.from_pretrained(VC_DEVICE)\n",
    "print(\"  Model loaded.\")\n",
    "\n",
    "# Process each reference voice\n",
    "for ref_path in ref_files:\n",
    "    voice_name = ref_path.stem\n",
    "    voice_out = Path(OUTPUT_DIR) / voice_name\n",
    "    voice_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    done, skipped, failed = 0, 0, 0\n",
    "    for src in tqdm(source_files, desc=f\"VC → {voice_name}\", unit=\"file\"):\n",
    "        rel = src.relative_to(INPUT_DIR)\n",
    "        dst = voice_out / rel\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if dst.exists():\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if VC_ENGINE == \"chatterbox_onnx\":\n",
    "                vc_model.voice_convert(\n",
    "                    source_audio_path=str(src),\n",
    "                    target_voice_path=str(ref_path),\n",
    "                    output_file_name=str(dst),\n",
    "                )\n",
    "            else:\n",
    "                import torchaudio as ta\n",
    "                wav = vc_model.generate(\n",
    "                    audio=str(src),\n",
    "                    target_voice_path=str(ref_path),\n",
    "                )\n",
    "                ta.save(str(dst), wav, vc_model.sr)\n",
    "            done += 1\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"  FAIL {src.name}: {e}\")\n",
    "            failed += 1\n",
    "\n",
    "    print(f\"  {voice_name}: {done} converted, {skipped} skipped, {failed} failed\")\n",
    "\n",
    "# Cleanup\n",
    "del vc_model\n",
    "try:\n",
    "    import torch\n",
    "    torch.cuda.empty_cache()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"\\nAll voices done.\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
